{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first step"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "from  PIL  import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('1234.jpg', cv.IMREAD_UNCHANGED)\n",
    "original = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = int(max(5, 6))\n",
    "u = int(min(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "edges = cv.GaussianBlur(img, (21, 51), 3)\n",
    "edges = cv.cvtColor(edges, cv.COLOR_BGR2GRAY)\n",
    "edges = cv.Canny(edges, l, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, thresh = cv.threshold(edges, 0, 255, cv.THRESH_BINARY  + cv.THRESH_OTSU)\n",
    "kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
    "mask = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel, iterations=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mask.tolist()\n",
    "sys.setrecursionlimit(10**8)\n",
    "for i in  range(len(data)):\n",
    "    for j in  range(len(data[i])):\n",
    "        if data[i][j] !=  255:\n",
    "            data[i][j] =  -1\n",
    "        else:\n",
    "            break\n",
    "    for j in  range(len(data[i])-1, -1, -1):\n",
    "        if data[i][j] !=  255:\n",
    "            data[i][j] =  -1\n",
    "        else:\n",
    "            break\n",
    "image = np.array(data)\n",
    "image[image !=  -1] =  255\n",
    "image[image ==  -1] =  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(image, np.uint8)\n",
    "\n",
    "result = cv.bitwise_and(original, original, mask=mask)\n",
    "result[mask ==  0] =  255\n",
    "cv.imwrite('bg.png', result)\n",
    "\n",
    "img = Image.open('bg.png')\n",
    "img.convert(\"RGBA\")\n",
    "datas = img.getdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = []\n",
    "for item in datas:\n",
    "    if item[0] ==  255  and item[1] ==  255  and item[2] ==  255:\n",
    "        newData.append((255, 255, 255, 0))\n",
    "    else:\n",
    "        newData.append(item)\n",
    "\n",
    "img.putdata(newData)\n",
    "img.save(\"img.png\", \"PNG\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The second Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Upload your file and define the filename input_file\n",
    "# Optional: Also upload or define the background file/url\n",
    "input_file = 'graduation.jpg'\n",
    "background_url = 'https://images.unsplash.com/photo-1475139441338-693e7dbe20b6?auto=format&fit=crop&w=640&q=427'\n",
    "\n",
    "background_file = 'background.jpg'\n",
    "foreground_file = 'foreground.png'\n",
    "output_file = 'final.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('background.jpg', <http.client.HTTPMessage at 0x226ec5613d0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# save the background \n",
    "urlretrieve(background_url, background_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "  model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "  model.eval()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transparent_foreground(pic, mask):\n",
    "  # split the image into channels\n",
    "  b, g, r = cv2.split(np.array(pic).astype('uint8'))\n",
    "  # add an alpha channel with and fill all with transparent pixels (max 255)\n",
    "  a = np.ones(mask.shape, dtype='uint8') * 255\n",
    "  # merge the alpha channel back\n",
    "  alpha_im = cv2.merge([b, g, r, a], 4)\n",
    "  # create a transparent background\n",
    "  bg = np.zeros(alpha_im.shape)\n",
    "  # setup the new mask\n",
    "  new_mask = np.stack([mask, mask, mask, mask], axis=2)\n",
    "  # copy only the foreground color pixels from the original image where mask is set\n",
    "  foreground = np.where(new_mask, alpha_im, bg).astype(np.uint8)\n",
    "\n",
    "  return foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(model, input_file):\n",
    "  input_image = Image.open(input_file)\n",
    "  preprocess = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ])\n",
    "\n",
    "  input_tensor = preprocess(input_image)\n",
    "  input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "  # move the input and model to GPU for speed if available\n",
    "  if torch.cuda.is_available():\n",
    "      input_batch = input_batch.to('cuda')\n",
    "      model.to('cuda')\n",
    "\n",
    "  with torch.no_grad():\n",
    "      output = model(input_batch)['out'][0]\n",
    "  output_predictions = output.argmax(0)\n",
    "  \n",
    "  # create a binary (black and white) mask of the profile foreground\n",
    "  mask = output_predictions.byte().cpu().numpy()\n",
    "  background = np.zeros(mask.shape)\n",
    "  bin_mask = np.where(mask, 255, background).astype(np.uint8)\n",
    "\n",
    "  foreground = make_transparent_foreground(input_image ,bin_mask)\n",
    "\n",
    "  return foreground, bin_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\LENOVO/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m deeplab_model \u001b[39m=\u001b[39m load_model()\n\u001b[1;32m----> 2\u001b[0m foreground, bin_mask \u001b[39m=\u001b[39m remove_background(deeplab_model, input_file)\n",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m, in \u001b[0;36mremove_background\u001b[1;34m(model, input_file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mremove_background\u001b[39m(model, input_file):\n\u001b[0;32m      2\u001b[0m   input_image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(input_file)\n\u001b[1;32m----> 3\u001b[0m   preprocess \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[0;32m      4\u001b[0m       transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[0;32m      5\u001b[0m       transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m], std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m]),\n\u001b[0;32m      6\u001b[0m   ])\n\u001b[0;32m      8\u001b[0m   input_tensor \u001b[39m=\u001b[39m preprocess(input_image)\n\u001b[0;32m      9\u001b[0m   input_batch \u001b[39m=\u001b[39m input_tensor\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39m# create a mini-batch as expected by the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "deeplab_model = load_model()\n",
    "foreground, bin_mask = remove_background(deeplab_model, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bin_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mimshow(bin_mask)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bin_mask' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(bin_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
